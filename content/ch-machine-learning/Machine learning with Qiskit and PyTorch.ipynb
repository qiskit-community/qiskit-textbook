{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid quantum-classical machine learning with PyTorch and Qiskit\n",
    "\n",
    "Machine learning has established itself as a successful multidisciplinary field that aims to create artificially intelligent systems by enabling machines to learn from data. Throwing in quantum computing gives rise to interesting areas of research that seek to leverage the principles of quantum mechanics for machine learning (ML) computation or vice-versa. Whether you're aiming to enhance classical ML algorithms by outsourcing difficult calculations to a quantum computer or optimise quantum algorithms using classical ML architectures - both are examples of [hybrid quantum-classical machine learning](https://pennylane.ai/qml/concepts.html#hybrid-computation). \n",
    "\n",
    "In this chapter, we introduce the notion of hybrid computation through a very simple example involving [neural networks](https://www.youtube.com/watch?v=aircAruvnKk) using the state-of-the-art open source software package - [PyTorch](https://pytorch.org/). The purpose of this example is to demonstrate the ease of integrating ML with Qiskit and to encourage ML practitioners to explore what is possible with quantum computing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>How does it work?</center></h1>\n",
    "<img src=\"hybridnetwork.png\" width = \"800\" />\n",
    "\n",
    "The figure above illustrates the framework we will construct in this chapter. Ultimately, we will create a hybrid quantum-classical neural network that optimises both classical and quantum parameters in order to do classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does that mean?\n",
    "Typically, a neural network takes in input data in the form of classical vectors. These inputs are multiplied by [weights](https://en.wikipedia.org/wiki/Artificial_neural_network#Connections_and_weights) which connect the inputs to neurons in the hidden layers of a neural network. The number of neurons in any hidden layer can be specified and often depend on the problem at hand. By creating a quantum-classical neural network, one can simply use a [parameterised quantum circuit](https://pennylane.ai/qml/concepts/varcirc.html) in any of the hidden layers where the neurons can now be thought of as the parameter values for the quantum circuit. The output of the quantum circuit are measurements that can act as values for neurons in the next hidden layer. In other words, there can be interplay between classical and quantum objects where the parameters of a [variational quantum circuit](https://pennylane.ai/qml/concepts/varcirc.html) are \"quantum neurons\" optimised through training of the weights in our neural network. The full neural network will thus seek to optimise over both classical and quantum parameters. A simple example is depicted below:\n",
    "\n",
    "<img src=\"neuralnetworkQC.png\" width = \"800\" />\n",
    "\n",
    "Here, $\\sigma$ is an [activation function](https://en.wikipedia.org/wiki/Activation_function) and $h_i$ is the value of neuron $i$ at each hidden layer. $R(h_i)$ represents any rotation gate about an angle equal to $h_i$ and $y$ is the final prediction value generated from the hybrid network.  \n",
    "\n",
    "### What about backpropagation?\n",
    "If you're familiar with classical ML, you may immediately be wondering *how do we calculate gradients when quantum circuits are involved?* This would be necessary to perform cool optimisation techniques like [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent). It gets a bit technical, but in short, we can view a quantum circuit as a black box and the gradient of this black box with respect to its parameters is calculated as follows: \n",
    "\n",
    "<img src=\"quantumgradient.png\" width = \"800\" />\n",
    "\n",
    "where $\\theta$ represents the parameters of the quantum circuit and $s$ is a macroscopic shift. Thus, the gradient is simply the difference between the quantum circuit evaluated at $\\theta+s$ and $\\theta - s$. The technical proof can be found [here](https://pennylane.ai/qml/concepts/autograd_quantum.html#a-more-technical-explanation) and this means that automatic differentiation with quantum circuits is not a problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Let's code!</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "First, we import some handy packages that we will need, including Qiskit and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister, execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors to lists\n",
    "Next we create an additional function that converts a tensor to a list in Python. This is needed to connect Qiskit and PyTorch objects. In particular, we will use this function to convert tensors produced by PyTorch to a list, such that they can be fed into quantum circuits in Qiskit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a \"quantum class\" with Qiskit\n",
    "We can conveniently put our Qiskit quantum functions into a class. First, we specify how many trainable quantum parameters and how many shots we wish to use in our quantum circuit. In this example, we will keep it simple and use a 1-qubit circuit with one trainable quantum parameter $\\theta$. We hard code the circuit for simplicity and use a $RY-$rotation by the angle $\\theta$ to train the output of our circuit. The circuit looks like this:\n",
    "\n",
    "<img src=\"1qubitcirc.png\" width = \"400\" />\n",
    "\n",
    "In order to measure the output in the $z-$basis, we create a Python function to obtain the $\\sigma_z$ expectation. Lastly, we create a \"bind\" function to convert our parameter to a list and run the circuit on the Aer simulator. We will see later how this all ties into the hybrid neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    # Specify initial parameters and the quantum circuit\n",
    "    \n",
    "    def __init__(self,shots):\n",
    "        self.theta = Parameter('Theta')\n",
    "        self.shots = shots\n",
    "        \n",
    "        def create_circuit():\n",
    "            qr = QuantumRegister(1,'q')\n",
    "            cr = ClassicalRegister(1,'c')\n",
    "            ckt = QuantumCircuit(qr,cr)\n",
    "            ckt.h(qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.ry(self.theta,qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.measure(qr,cr)\n",
    "            return ckt\n",
    "        \n",
    "        self.circuit = create_circuit()\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects    \n",
    "    \n",
    "    def bind(self, parameters):\n",
    "        [self.theta] = to_numbers(parameters)\n",
    "        self.circuit.data[2][0]._params = to_numbers(parameters)\n",
    "    \n",
    "    def run(self, i):\n",
    "        self.bind(i)\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,backend,shots=self.shots)\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a \"quantum-classical class\" with PyTorch\n",
    "Now that our quantum circuit is defined, we can create the functions needed for backpropagation using PyTorch. [The forward and backward passes](http://www.ai.mit.edu/courses/6.034b/backprops.pdf) contain elements from our Qiskit class. The backward pass directly computes the analytical gradients using the finite difference formula we introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(shots=100)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i[0])\n",
    "        \n",
    "        result = torch.tensor([exp_value]) # store the result as a torch tensor\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        s = np.pi/2\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors  \n",
    "        \n",
    "        # Obtain paramaters \n",
    "        input_numbers = to_numbers(i[0])\n",
    "        \n",
    "        gradient = []\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_plus_s = input_numbers\n",
    "            input_plus_s[k] = input_numbers[k] + s  # Shift up by s\n",
    "            \n",
    "            exp_value_plus = ctx.QiskitCirc.run(torch.tensor(input_plus_s))[0]\n",
    "            result_plus_s = torch.tensor([exp_value_plus])\n",
    "            \n",
    "            input_minus_s = input_numbers\n",
    "            input_minus_s[k] = input_numbers[k] - s # Shift down by s\n",
    "            \n",
    "            exp_value_minus = ctx.QiskitCirc.run(torch.tensor(input_minus_s))[0]\n",
    "            result_minus_s = torch.tensor([exp_value_minus])\n",
    "\n",
    "            gradient_result = (result_plus_s - result_minus_s)\n",
    "\n",
    "            gradient.append(gradient_result)\n",
    "            \n",
    "        result = torch.tensor([gradient])\n",
    "        \n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Putting this all together</center></h1>\n",
    "We will create a simple hybrid neural network to classify images of two types of digits (0 or 1) from the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). We first load MNIST and filter for pictures containing 0's and 1's. These will serve as inputs for our neural network to classify.\n",
    "\n",
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()]) # transform images to tensors/vectors\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets # get the labels for the data\n",
    "labels = labels.numpy()\n",
    "\n",
    "idx1 = np.where(labels == 0) # filter on zeros\n",
    "idx2 = np.where(labels == 1) # filter on ones\n",
    "\n",
    "# Specify number of datapoints per class (i.e. there will be n pictures of 1 and n pictures of 0 in the training set)\n",
    "n=100\n",
    "\n",
    "# concatenate the data indices\n",
    "idx = np.concatenate((idx1[0][0:n],idx2[0][0:n])) \n",
    "\n",
    "# create the filtered dataset for our training set\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will consist of images belonging to two classes: 0 and 1. An example image from both classes looks like this:\n",
    "\n",
    "<img src=\"MNISTplot.png\" width = \"100\" />\n",
    "\n",
    "So far, we have loaded the data and coded a class that creates our quantum circuit which contains 1 trainable parameter. This quantum parameter will be inserted into a classical neural network along with the other classical parameters to form the hybrid neural network. We also created backward and forward pass functions that allow us to do backpropagation and optimise our neural network. Lastly, we need to specify our neural network architecture such that we can begin to train our parameters using optimisation techniques provided by PyTorch. \n",
    "\n",
    "\n",
    "### Creating the hybrid neural network\n",
    "We can use a neat PyTorch pipeline to create a neural network architecture. The network will need to be compatible in terms of its dimensionality when we insert the quantum node (i.e. our quantum circuit). Since our quantum node in this example contains 1 parameter, we must ensure the network condenses neurons down to size 1. We create a network consisting of 3 hidden layers with 320, 50 and 1 neurons respectively. The value of the last neuron is fed as the parameter $\\theta$ into our quantum circuit. The circuit measurement then serves as the final prediction for 0 or 1 as provided by a $\\sigma_z$ measurement. The measurement outcomes are -1 which implies a predicted label of 0 and 1 which implies a predicted label of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = TorchCircuit.apply \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.h1 = nn.Linear(320, 50)\n",
    "        self.h2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.h1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.h2(x)\n",
    "        x = qc(x)\n",
    "        x = (x+1)/2  # Normalise the inputs to 1 or 0\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "We now have all the ingredients to train our hybrid network! We can specify any [PyTorch optimiser](https://pytorch.org/docs/stable/optim.html), [learning rate](https://en.wikipedia.org/wiki/Learning_rate) and [cost/loss function](https://en.wikipedia.org/wiki/Loss_function) in order to train over multiple epochs. In this instance, we use the [Adam optimiser](https://arxiv.org/abs/1412.6980), a learning rate of 0.001 and the [negative log-likelihood loss function](https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6282500000000002\n",
      "-0.7656999999999999\n",
      "-0.7852499999999991\n",
      "-0.7806500000000003\n",
      "-0.7706499999999997\n",
      "-0.7907499999999998\n",
      "-0.7934999999999997\n",
      "-0.8000499999999994\n",
      "-0.8040500000000005\n",
      "-0.8073999999999997\n",
      "-0.7906999999999997\n",
      "-0.8235499999999996\n",
      "-0.8144499999999997\n",
      "-0.8119499999999998\n",
      "-0.8192499999999998\n",
      "-0.8231999999999998\n",
      "-0.8070500000000002\n",
      "-0.8279000000000003\n",
      "-0.8181\n",
      "-0.825\n",
      "-0.8253499999999998\n",
      "-0.8277500000000004\n",
      "-0.8234999999999996\n",
      "-0.8311999999999995\n",
      "-0.8251000000000002\n",
      "-0.83265\n",
      "-0.8251\n",
      "-0.8250499999999996\n",
      "-0.8258999999999997\n",
      "-0.8252000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13228e0b8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = Net()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 30\n",
    "loss_list = []\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    target_list = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target_list.append(target.item())\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.item())\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print(loss_list[-1])\n",
    "\n",
    "# Normalise the loss between 0 and 1\n",
    "for i in range(len(loss_list)):\n",
    "    loss_list[i] += 1\n",
    "\n",
    "# Plot the loss per epoch\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What now?\n",
    "While it is totally possible to create hybrid neural networks, does this actually have any benefit? In fact, the classical layers of this network train perfectly fine (if not better) without the quantum node. The point of this exercise is to get you to start thinking about integrating techniques from ML and quantum computing in order to investigate if there is indeed some element of interest - and thanks to PyTorch and Qiskit, this becomes a little bit easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notebook author: Amira Abbas (amyami187@gmail.com)*.\n",
    "*Code contributors: Karel Dumon, Patrick Huembeli, Amira Abbas, Isaac Turtletaub, Christa Zoufal.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
